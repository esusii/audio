import numpy as np
import cupy as cp
import matplotlib.pyplot as plt
import pyaudio
from time import sleep

def gpu_stft(x, fs, window, nperseg, noverlap):
    step = nperseg - noverlap
    n_frames = (len(x) - noverlap) // step
    result = cp.empty((nperseg // 2 + 1, n_frames), dtype=cp.complex64)
    for i in range(n_frames):
        frame = x[i * step:i * step + nperseg] * window
        result[:, i] = cp.fft.rfft(frame)
    f = cp.fft.rfftfreq(nperseg, 1 / fs)
    t = cp.arange(n_frames) * step / fs
    return f, t, result

# Parameters
CHUNK = 1024
RATE = 44100
WINDOW = cp.hanning(512)
NPERSEG = 512
OVERLAP = NPERSEG // 2
DURATION = 5  # Duration to record in seconds
MAX_FRAMES = int(DURATION * RATE / CHUNK)
N_FRAMES_PLOT = 100  # Number of frames to plot

# Initialize PyAudio
audio = pyaudio.PyAudio()
stream = audio.open(format=pyaudio.paFloat32, channels=1, rate=RATE, input=True, frames_per_buffer=CHUNK)

# Initialize the plot
plt.ion()
fig, ax = plt.subplots()

# Record and process audio in chunks
frames = []
for i in range(MAX_FRAMES):
    data = cp.asarray(np.frombuffer(stream.read(CHUNK), dtype=np.float32))

    frames.append(data)

    # Only process and plot the most recent frames
    if len(frames) > N_FRAMES_PLOT:
        frames.pop(0)
    signal = cp.concatenate(frames)
    f, t, Zxx = gpu_stft(signal, RATE, WINDOW, NPERSEG, OVERLAP)
    ax.pcolormesh(cp.asnumpy(t[-N_FRAMES_PLOT:]), cp.asnumpy(f), cp.asnumpy(cp.abs(Zxx[:, -N_FRAMES_PLOT:])), shading='gouraud')
    ax.set_ylim(0, 5000)
    ax.set_xlabel('Time [s]')
    ax.set_ylabel('Frequency [Hz]')
    plt.pause(0.001)
    ax.clear()

    # Sleep to simulate a live feed
    sleep(CHUNK / RATE)

# Close the stream and PyAudio
stream.stop_stream()
stream.close()
audio.terminate()
